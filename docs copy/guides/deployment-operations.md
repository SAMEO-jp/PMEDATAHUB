# ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»é‹ç”¨ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€PME DATAHUB ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã€é‹ç”¨ã€ä¿å®ˆã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªæ‰‹é †ã‚’å®šç¾©ã™ã‚‹ã€‚æœ¬ç•ªç’°å¢ƒã§ã®å®‰å®šã—ãŸé‹ç”¨ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã®æ¨™æº–çš„ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’è¨˜è¿°ã™ã‚‹ã€‚

## 1. ç’°å¢ƒæ§‹æˆ

### 1.1 ç’°å¢ƒåŒºåˆ†

| ç’°å¢ƒ | ç›®çš„ | ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ | ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ |
|------|------|--------------|------------|
| **é–‹ç™ºç’°å¢ƒ** | æ©Ÿèƒ½é–‹ç™ºãƒ»å˜ä½“ãƒ†ã‚¹ãƒˆ | é–‹ç™ºè€…ãƒãƒ¼ãƒ  | ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ |
| **ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒ** | çµ±åˆãƒ†ã‚¹ãƒˆãƒ»UAT | é–‹ç™ºãƒ»QAãƒãƒ¼ãƒ  | æœ¬ç•ªç›¸å½“ãƒ‡ãƒ¼ã‚¿ |
| **æœ¬ç•ªç’°å¢ƒ** | æ¥­å‹™é‹ç”¨ | å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ | å®Ÿæ¥­å‹™ãƒ‡ãƒ¼ã‚¿ |

### 1.2 ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£è¦ä»¶

#### ã‚µãƒ¼ãƒãƒ¼è¦ä»¶
```yaml
# æœ€å°è¦ä»¶
CPU: 2ã‚³ã‚¢ä»¥ä¸Š
RAM: 4GBä»¥ä¸Š
Storage: 50GB SSDä»¥ä¸Š
Network: 100Mbpsä»¥ä¸Š

# æ¨å¥¨è¦ä»¶ï¼ˆ50ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ¨¡ï¼‰
CPU: 4ã‚³ã‚¢ä»¥ä¸Š
RAM: 8GBä»¥ä¸Š
Storage: 100GB SSDä»¥ä¸Š
Network: 1Gbpsä»¥ä¸Š
```

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¦ä»¶
```yaml
# SQLite è¨­å®š
max_connections: 100
cache_size: 100MB
temp_store: memory
journal_mode: WAL
synchronous: NORMAL
```

## 2. ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### 2.1 è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### ãƒ¡ã‚¤ãƒ³ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# scripts/deploy.sh

set -e  # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«åœæ­¢

# è¨­å®š
ENVIRONMENT=${1:-production}
VERSION=$(git rev-parse HEAD)
DEPLOY_DIR="/var/www/pme-datahub"
BACKUP_DIR="/var/backups/pme-datahub"

echo "ğŸš€ Starting deployment to $ENVIRONMENT environment"
echo "ğŸ“¦ Version: $VERSION"

# äº‹å‰ãƒã‚§ãƒƒã‚¯
echo "ğŸ” Running pre-deployment checks..."
npm run typecheck
npm run lint
npm run test

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "ğŸ’¾ Creating database backup..."
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="$BACKUP_DIR/achievements_pre_deploy_$TIMESTAMP.db"
sqlite3 data/achievements.db ".backup '$BACKUP_FILE'"

# ãƒ“ãƒ«ãƒ‰
echo "ğŸ”¨ Building application..."
if [ "$ENVIRONMENT" = "production" ]; then
  npm run build:standalone
else
  npm run build
fi

# ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
echo "ğŸ›‘ Stopping application service..."
sudo systemctl stop pme-datahub || true

# ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®
echo "ğŸ“ Deploying files..."
sudo rsync -av --delete \
  --exclude='.git' \
  --exclude='node_modules' \
  --exclude='.env*' \
  ./ "$DEPLOY_DIR/"

# æ¨©é™è¨­å®š
echo "ğŸ”’ Setting permissions..."
sudo chown -R www-data:www-data "$DEPLOY_DIR"
sudo chmod -R 755 "$DEPLOY_DIR"
sudo chmod 600 "$DEPLOY_DIR/data/achievements.db"

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
echo "ğŸ—ƒï¸ Running database migrations..."
cd "$DEPLOY_DIR"
npm run db:migrate

# ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•
echo "â–¶ï¸ Starting application service..."
sudo systemctl start pme-datahub
sudo systemctl enable pme-datahub

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo "ğŸ¥ Running health checks..."
sleep 10
if curl -f http://localhost:3000/api/health; then
  echo "âœ… Deployment successful!"

  # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ­ã‚°è¨˜éŒ²
  echo "$TIMESTAMP|$VERSION|$ENVIRONMENT|SUCCESS" >> "$DEPLOY_DIR/deploy.log"

else
  echo "âŒ Deployment failed! Rolling back..."

  # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
  ./scripts/rollback.sh "$BACKUP_FILE"

  exit 1
fi
```

#### ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# scripts/rollback.sh

BACKUP_FILE="$1"

if [ -z "$BACKUP_FILE" ]; then
  echo "Usage: $0 <backup_file>"
  exit 1
fi

echo "ğŸ”„ Starting rollback..."

# ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
sudo systemctl stop pme-datahub

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©æ—§
echo "ğŸ—ƒï¸ Restoring database..."
cp "$BACKUP_FILE" data/achievements.db

# ä»¥å‰ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆ‡ã‚Šæˆ»ã—
if [ -d "previous_version" ]; then
  echo "ğŸ“ Restoring previous version..."
  rsync -av --delete previous_version/ ./
fi

# ã‚µãƒ¼ãƒ“ã‚¹å†é–‹
sudo systemctl start pme-datahub

echo "âœ… Rollback completed"
```

### 2.2 Docker ãƒ‡ãƒ—ãƒ­ã‚¤

#### Dockerfile
```dockerfile
# Dockerfile
FROM node:18-alpine AS base

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
FROM base AS deps
RUN apk add --no-cache libc6-compat
WORKDIR /app

COPY package.json package-lock.json ./
RUN npm ci --only=production

# ãƒ“ãƒ«ãƒ‰
FROM base AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .

ENV NEXT_TELEMETRY_DISABLED 1
RUN npm run build

# å®Ÿè¡Œç’°å¢ƒ
FROM base AS runner
WORKDIR /app

ENV NODE_ENV production
ENV NEXT_TELEMETRY_DISABLED 1

RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

# ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å‡ºåŠ›ã®ã‚³ãƒ”ãƒ¼
COPY --from=builder /app/public ./public
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs

EXPOSE 3000
ENV PORT 3000

CMD ["node", "server.js"]
```

#### docker-compose.yml
```yaml
version: '3.8'

services:
  pme-datahub:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=file:/app/data/achievements.db
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/ssl/certs:ro
    depends_on:
      - pme-datahub
    restart: unless-stopped
```

## 3. ç›£è¦–ãƒ»ãƒ­ã‚°ç®¡ç†

### 3.1 ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç›£è¦–

#### ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
```typescript
// app/api/health/route.ts
import { NextResponse } from 'next/server';
import { prisma } from '@/lib/prisma';

export async function GET() {
  try {
    // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒã‚§ãƒƒã‚¯
    await prisma.$queryRaw`SELECT 1`;

    // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
    const memUsage = process.memoryUsage();
    const isMemoryOk = memUsage.heapUsed / memUsage.heapTotal < 0.9;

    // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ï¼‰
    const startTime = Date.now();

    // åŸºæœ¬çš„ãªã‚¯ã‚¨ãƒªå®Ÿè¡Œ
    const projectCount = await prisma.project.count();

    const responseTime = Date.now() - startTime;

    const health = {
      status: 'healthy',
      timestamp: new Date().toISOString(),
      services: {
        database: 'up',
        memory: isMemoryOk ? 'ok' : 'high',
        response_time: `${responseTime}ms`
      },
      metrics: {
        projects: projectCount,
        uptime: process.uptime(),
        memory: {
          used: Math.round(memUsage.heapUsed / 1024 / 1024),
          total: Math.round(memUsage.heapTotal / 1024 / 1024),
          external: Math.round(memUsage.external / 1024 / 1024)
        }
      }
    };

    return NextResponse.json(health);

  } catch (error) {
    console.error('Health check failed:', error);

    return NextResponse.json({
      status: 'unhealthy',
      timestamp: new Date().toISOString(),
      error: error.message
    }, { status: 503 });
  }
}
```

#### ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
```typescript
// lib/monitoring/metrics.ts
import { collectDefaultMetrics, Registry } from 'prom-client';

export class MetricsCollector {
  private register: Registry;

  constructor() {
    this.register = new Registry();
    collectDefaultMetrics({ register: this.register });

    // ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    this.registerGauge('active_users', 'Number of active users');
    this.registerCounter('api_requests_total', 'Total API requests');
    this.registerHistogram('api_request_duration', 'API request duration');
  }

  private registerGauge(name: string, help: string) {
    new promClient.Gauge({
      name,
      help,
      registers: [this.register]
    });
  }

  private registerCounter(name: string, help: string) {
    new promClient.Counter({
      name,
      help,
      registers: [this.register]
    });
  }

  private registerHistogram(name: string, help: string) {
    new promClient.Histogram({
      name,
      help,
      registers: [this.register]
    });
  }

  getMetrics(): Promise<string> {
    return this.register.metrics();
  }

  // ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°ãƒ¡ã‚½ãƒƒãƒ‰
  incrementApiRequests(endpoint: string) {
    // APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ
  }

  recordApiDuration(endpoint: string, duration: number) {
    // APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ ã®è¨˜éŒ²
  }

  setActiveUsers(count: number) {
    // ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã®è¨­å®š
  }
}
```

### 3.2 ãƒ­ã‚°ç®¡ç†

#### æ§‹é€ åŒ–ãƒ­ã‚°è¨­å®š
```typescript
// lib/logging/logger.ts
import winston from 'winston';

export const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: { service: 'pme-datahub' },
  transports: [
    // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      )
    }),

    // ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    new winston.transports.File({
      filename: 'logs/error.log',
      level: 'error',
      maxsize: 5242880, // 5MB
      maxFiles: 5
    }),

    new winston.transports.File({
      filename: 'logs/combined.log',
      maxsize: 5242880, // 5MB
      maxFiles: 5
    })
  ]
});

// ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
export function requestLogger(req: NextRequest, res: NextResponse) {
  const start = Date.now();

  logger.info('Request started', {
    method: req.method,
    url: req.url,
    ip: req.ip,
    userAgent: req.headers.get('user-agent')
  });

  // ãƒ¬ã‚¹ãƒãƒ³ã‚¹å¾Œã®ãƒ­ã‚°
  const originalEnd = res.end;
  res.end = function(...args) {
    const duration = Date.now() - start;

    logger.info('Request completed', {
      method: req.method,
      url: req.url,
      statusCode: res.status,
      duration: `${duration}ms`
    });

    originalEnd.apply(this, args);
  };
}
```

#### ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
```bash
# logrotateè¨­å®š /etc/logrotate.d/pme-datahub
/var/www/pme-datahub/logs/*.log {
    daily
    missingok
    rotate 7
    compress
    delaycompress
    notifempty
    create 644 www-data www-data
    postrotate
        systemctl reload pme-datahub
    endscript
}
```

## 4. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»å¾©æ—§

### 4.1 è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š

#### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_ROOT="/var/backups/pme-datahub"
DATE=$(date +%Y%m%d)
TIME=$(date +%H%M%S)
BACKUP_DIR="$BACKUP_ROOT/$DATE"
BACKUP_FILE="$BACKUP_DIR/achievements_$TIME.db"

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p "$BACKUP_DIR"

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "Creating database backup..."
sqlite3 /var/www/pme-datahub/data/achievements.db ".backup '$BACKUP_FILE'"

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
cp /var/www/pme-datahub/.env.production "$BACKUP_DIR/.env.production"

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
cp -r /var/www/pme-datahub/logs "$BACKUP_DIR/"

# åœ§ç¸®
echo "Compressing backup..."
tar -czf "$BACKUP_DIR.tar.gz" -C "$BACKUP_ROOT" "$DATE"
rm -rf "$BACKUP_DIR"

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ï¼ˆ30æ—¥ä»¥ä¸Šå‰ï¼‰
find "$BACKUP_ROOT" -name "*.tar.gz" -mtime +30 -delete

# S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
if [ -n "$AWS_S3_BUCKET" ]; then
  aws s3 cp "$BACKUP_DIR.tar.gz" "s3://$AWS_S3_BUCKET/backups/"
fi

echo "Backup completed: $BACKUP_DIR.tar.gz"
```

#### å®šæœŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
```bash
# crontab -e

# æ¯æœ2:00ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
0 2 * * * /var/www/pme-datahub/scripts/backup.sh

# æ¯é€±æ—¥æ›œæ—¥3:00ã«ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
0 3 * * 0 /var/www/pme-datahub/scripts/full-backup.sh

# æ¯æœˆ1æ—¥4:00ã«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
0 4 1 * * /var/www/pme-datahub/scripts/archive-backup.sh
```

### 4.2 éšœå®³å¾©æ—§æ‰‹é †

#### å¾©æ—§å„ªå…ˆåº¦åˆ†é¡
1. **ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«**: ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ãŒåœæ­¢
2. **é«˜**: ä¸»è¦æ©Ÿèƒ½ãŒä½¿ç”¨ä¸èƒ½
3. **ä¸­**: ä¸€éƒ¨æ©Ÿèƒ½ãŒä½¿ç”¨ä¸èƒ½
4. **ä½**: è»½å¾®ãªå•é¡Œ

#### å¾©æ—§æ‰‹é †æ›¸
```markdown
# ã‚·ã‚¹ãƒ†ãƒ éšœå®³å¾©æ—§æ‰‹é †

## 1. éšœå®³æ¤œçŸ¥
- ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ©ãƒ¼ãƒˆ
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å ±å‘Š
- ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®å¤±æ•—

## 2. åˆæœŸè©•ä¾¡
### ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«éšœå®³
1. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒšãƒ¼ã‚¸æ›´æ–°
2. é–¢ä¿‚è€…ã¸ã®ç·Šæ€¥é€£çµ¡
3. å¾©æ—§ãƒãƒ¼ãƒ æ‹›é›†

### ãã®ä»–ã®éšœå®³
1. éšœå®³å†…å®¹ã®è©³ç´°ç¢ºèª
2. å½±éŸ¿ç¯„å›²ã®ç‰¹å®š
3. å¾©æ—§å„ªå…ˆåº¦ã®æ±ºå®š

## 3. å¾©æ—§å®Ÿè¡Œ
### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹éšœå®³
```bash
# ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
sudo systemctl stop pme-datahub

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©æ—§
/var/www/pme-datahub/scripts/restore.sh /var/backups/latest.db

# ã‚µãƒ¼ãƒ“ã‚¹å†é–‹
sudo systemctl start pme-datahub
```

### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³éšœå®³
```bash
# ãƒ­ã‚°ç¢ºèª
tail -f /var/www/pme-datahub/logs/error.log

# ãƒ—ãƒ­ã‚»ã‚¹å†é–‹
sudo systemctl restart pme-datahub

# å•é¡ŒãŒè§£æ±ºã—ãªã„å ´åˆ
# ä»¥å‰ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
/var/www/pme-datahub/scripts/rollback.sh
```

## 4. é€šä¿¡ãƒ»å ±å‘Š
- **å†…éƒ¨**: å¾©æ—§çŠ¶æ³ã‚’é–¢ä¿‚è€…ã«éšæ™‚å ±å‘Š
- **å¤–éƒ¨**: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒšãƒ¼ã‚¸ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«çŠ¶æ³ã‚’å…¬é–‹
- **å®Œäº†å ±å‘Š**: å¾©æ—§å®Œäº†å¾Œã€è©³ç´°ãªå ±å‘Šæ›¸ã‚’ä½œæˆ
```

## 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 5.1 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–

#### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
```sql
-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆæ›´æ–°
ANALYZE;

-- ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç‰¹å®š
SELECT
  schemaname,
  tablename,
  indexname,
  idx_scan,
  pg_size_pretty(pg_relation_size(indexrelid))
FROM pg_stat_user_indexes
WHERE idx_scan = 0
ORDER BY pg_relation_size(indexrelid) DESC;

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰
REINDEX INDEX CONCURRENTLY index_name;
```

#### ã‚¯ã‚¨ãƒªæœ€é©åŒ–
```typescript
// åŠ¹ç‡çš„ãªã‚¯ã‚¨ãƒªä¾‹
export async function getProjectsWithStats(userId: string) {
  // N+1å•é¡Œã‚’é¿ã‘ã‚‹ãŸã‚ã€ä¸€åº¦ã®ã‚¯ã‚¨ãƒªã§å–å¾—
  const projects = await prisma.project.findMany({
    where: {
      OR: [
        { ownerId: userId },
        { members: { some: { userId } } }
      ]
    },
    include: {
      members: {
        select: { userId: true, role: true }
      },
      _count: {
        select: { tasks: true }
      }
    }
  });

  return projects.map(project => ({
    ...project,
    memberCount: project.members.length,
    taskCount: project._count.tasks
  }));
}
```

### 5.2 ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥

#### Redis ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
```typescript
// lib/cache/redis.ts
import { Redis } from 'ioredis';

export class CacheManager {
  private redis: Redis;

  constructor() {
    this.redis = new Redis(process.env.REDIS_URL);
  }

  async get<T>(key: string): Promise<T | null> {
    const data = await this.redis.get(key);
    return data ? JSON.parse(data) : null;
  }

  async set(key: string, value: any, ttlSeconds?: number): Promise<void> {
    const data = JSON.stringify(value);

    if (ttlSeconds) {
      await this.redis.setex(key, ttlSeconds, data);
    } else {
      await this.redis.set(key, data);
    }
  }

  async invalidate(pattern: string): Promise<void> {
    const keys = await this.redis.keys(pattern);
    if (keys.length > 0) {
      await this.redis.del(...keys);
    }
  }
}

// ä½¿ç”¨ä¾‹
export async function getCachedProjects(userId: string) {
  const cacheKey = `projects:user:${userId}`;
  const cache = new CacheManager();

  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
  let projects = await cache.get(cacheKey);

  if (!projects) {
    // DBã‹ã‚‰å–å¾—
    projects = await getProjectsWithStats(userId);

    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ï¼ˆ10åˆ†ï¼‰
    await cache.set(cacheKey, projects, 600);
  }

  return projects;
}
```

## 6. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æˆ¦ç•¥

### 6.1 æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

#### ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼è¨­å®š
```nginx
# nginx.conf
upstream pme_app {
    ip_hash;  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶­æŒã®ãŸã‚
    server app1.example.com:3000;
    server app2.example.com:3000;
    server app3.example.com:3000;
}

server {
    listen 80;
    server_name pme-datahub.example.com;

    location / {
        proxy_pass http://pme_app;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
    }

    # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    location /_next/static/ {
        proxy_pass http://pme_app;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

#### ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒˆã‚¢å…±æœ‰
```typescript
// Redis ã‚’ä½¿ç”¨ã—ãŸã‚»ãƒƒã‚·ãƒ§ãƒ³å…±æœ‰
export const sessionConfig = {
  store: new RedisStore({
    client: redisClient,
    prefix: 'session:',
    ttl: 86400 // 24æ™‚é–“
  }),
  secret: process.env.SESSION_SECRET,
  resave: false,
  saveUninitialized: false,
  cookie: {
    secure: process.env.NODE_ENV === 'production',
    httpOnly: true,
    maxAge: 24 * 60 * 60 * 1000 // 24æ™‚é–“
  }
};
```

### 6.2 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

#### Read Replica è¨­å®š
```typescript
// lib/prisma/replica.ts
export const prismaReplica = new PrismaClient({
  datasources: {
    db: {
      url: process.env.DATABASE_REPLICA_URL
    }
  }
});

// èª­ã¿å–ã‚Šå°‚ç”¨ã‚¯ã‚¨ãƒªã«ãƒ¬ãƒ—ãƒªã‚«ã‚’ä½¿ç”¨
export async function getProjectsReadOnly() {
  return await prismaReplica.project.findMany({
    // èª­ã¿å–ã‚Šå°‚ç”¨æ“ä½œ
  });
}
```

#### ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æº–å‚™
```typescript
// lib/database/sharding.ts
export class DatabaseSharding {
  private shards: Map<string, PrismaClient> = new Map();

  constructor(shardConfigs: ShardConfig[]) {
    for (const config of shardConfigs) {
      this.shards.set(config.id, new PrismaClient({
        datasources: { db: { url: config.url } }
      }));
    }
  }

  getShard(projectId: string): PrismaClient {
    // ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã«åŸºã¥ãã‚·ãƒ£ãƒ¼ãƒ‰é¸æŠ
    const shardId = this.getShardId(projectId);
    return this.shards.get(shardId)!;
  }

  private getShardId(projectId: string): string {
    // ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    const hash = this.simpleHash(projectId);
    return `shard_${hash % this.shards.size}`;
  }

  private simpleHash(str: string): number {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      hash = ((hash << 5) - hash + str.charCodeAt(i)) & 0xffffffff;
    }
    return Math.abs(hash);
  }
}
```

## 7. å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

### 7.1 ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦

#### å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
- **æ—¥æ¬¡**: ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€è»½å¾®ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
- **é€±æ¬¡**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ãƒƒãƒé©ç”¨
- **æœˆæ¬¡**: ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã€åŒ…æ‹¬çš„ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
- **å››åŠæœŸ**: å¤§è¦æ¨¡ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- **å¹´æ¬¡**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¦‹ç›´ã—ã€æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯æ›´æ–°

#### ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
```typescript
// lib/maintenance/notifier.ts
export class MaintenanceNotifier {
  static async scheduleMaintenance(
    title: string,
    description: string,
    startTime: Date,
    durationMinutes: number
  ) {
    const maintenance = {
      id: generateId(),
      title,
      description,
      startTime,
      endTime: new Date(startTime.getTime() + durationMinutes * 60 * 1000),
      status: 'scheduled'
    };

    // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¨˜éŒ²
    await prisma.maintenance_schedule.create({ data: maintenance });

    // ãƒ¦ãƒ¼ã‚¶ãƒ¼é€šçŸ¥
    await this.notifyUsers(maintenance);

    // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒšãƒ¼ã‚¸æ›´æ–°
    await this.updateStatusPage(maintenance);

    return maintenance;
  }

  private static async notifyUsers(maintenance: MaintenanceSchedule) {
    // ãƒ¡ãƒ¼ãƒ«é€šçŸ¥
    const users = await prisma.users.findMany({
      where: { notification_enabled: true }
    });

    for (const user of users) {
      await sendEmail({
        to: user.email,
        subject: `ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹é€šçŸ¥: ${maintenance.title}`,
        body: this.formatMaintenanceEmail(maintenance)
      });
    }
  }
}
```

### 7.2 ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ãƒ»ãƒ¬ãƒãƒ¼ãƒˆ

#### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
```typescript
// lib/reporting/performance-report.ts
export class PerformanceReporter {
  static async generateMonthlyReport(year: number, month: number) {
    const startDate = new Date(year, month - 1, 1);
    const endDate = new Date(year, month, 1);

    // å„ç¨®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é›†è¨ˆ
    const metrics = await this.collectMetrics(startDate, endDate);

    const report = {
      period: { year, month },
      summary: {
        totalUsers: metrics.uniqueUsers,
        totalRequests: metrics.totalRequests,
        averageResponseTime: metrics.avgResponseTime,
        errorRate: metrics.errorRate,
        uptime: metrics.uptimePercentage
      },
      performance: {
        responseTimeTrend: metrics.responseTimeTrend,
        errorTrend: metrics.errorTrend,
        resourceUsage: metrics.resourceUsage
      },
      incidents: await this.getIncidents(startDate, endDate),
      recommendations: this.generateRecommendations(metrics)
    };

    // ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    await this.saveReport(report);

    // ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®é€šçŸ¥
    await this.distributeReport(report);

    return report;
  }

  private static async collectMetrics(startDate: Date, endDate: Date) {
    // ç›£è¦–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’é›†è¨ˆ
    const [requests, errors, performance] = await Promise.all([
      this.getRequestMetrics(startDate, endDate),
      this.getErrorMetrics(startDate, endDate),
      this.getPerformanceMetrics(startDate, endDate)
    ]);

    return {
      uniqueUsers: requests.uniqueUsers,
      totalRequests: requests.total,
      avgResponseTime: performance.averageResponseTime,
      errorRate: (errors.total / requests.total) * 100,
      uptimePercentage: performance.uptimePercentage,
      responseTimeTrend: performance.trend,
      errorTrend: errors.trend,
      resourceUsage: performance.resourceUsage
    };
  }
}
```

---

## 8. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é‹ç”¨

### 8.1 å®šæœŸã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯

#### è‡ªå‹•ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
```bash
#!/bin/bash
# scripts/security-scan.sh

echo "ğŸ”’ Starting security scan..."

# ä¾å­˜é–¢ä¿‚è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯
echo "Checking dependencies..."
npm audit --audit-level moderate

# ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ãƒã‚§ãƒƒã‚¯
echo "Checking file permissions..."
find /var/www/pme-datahub -type f -perm /o+w -ls

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
echo "Checking database security..."
sqlite3 data/achievements.db "SELECT sql FROM sqlite_master WHERE type='table';" | grep -i "password\|secret"

# ãƒ­ã‚°ç›£æŸ»
echo "Checking recent suspicious activities..."
grep -i "failed\|error\|unauthorized" /var/log/pme-datahub/*.log | tail -20

echo "Security scan completed"
```

#### ä¾µå…¥æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
```typescript
// lib/security/ids.ts
export class IntrusionDetectionSystem {
  private static readonly ALERT_THRESHOLDS = {
    failedLoginsPerMinute: 10,
    suspiciousRequestsPerMinute: 50,
    largePayloadSize: 10 * 1024 * 1024 // 10MB
  };

  static async monitorTraffic(req: NextRequest): Promise<void> {
    const clientIP = req.ip;
    const now = Date.now();

    // ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
    const isRateLimited = await this.checkRateLimit(clientIP, now);
    if (isRateLimited) {
      await SecurityAlertSystem.alertSecurityEvent('rate_limit_exceeded', {
        ip: clientIP,
        path: req.nextUrl.pathname,
        userAgent: req.headers.get('user-agent')
      });
    }

    // ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
    const contentLength = parseInt(req.headers.get('content-length') || '0');
    if (contentLength > this.ALERT_THRESHOLDS.largePayloadSize) {
      await SecurityAlertSystem.alertSecurityEvent('large_payload_detected', {
        ip: clientIP,
        size: contentLength,
        path: req.nextUrl.pathname
      });
    }

    // ä¸å¯©ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
    if (this.isSuspiciousRequest(req)) {
      await SecurityAlertSystem.alertSecurityEvent('suspicious_request', {
        ip: clientIP,
        path: req.nextUrl.pathname,
        method: req.method,
        headers: Object.fromEntries(req.headers)
      });
    }
  }

  private static async checkRateLimit(ip: string, timestamp: number): Promise<boolean> {
    // Redisã‚’ä½¿ç”¨ã—ã¦ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å®Ÿè£…
    const key = `rate_limit:${ip}`;
    const windowStart = timestamp - 60000; // 1åˆ†é–“

    const requestCount = await redis.zcount(key, windowStart, timestamp);

    if (requestCount >= this.ALERT_THRESHOLDS.failedLoginsPerMinute) {
      return true;
    }

    // ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¨˜éŒ²
    await redis.zadd(key, timestamp, timestamp);
    await redis.expire(key, 60); // 1åˆ†å¾Œã« expire

    return false;
  }

  private static isSuspiciousRequest(req: NextRequest): boolean {
    const path = req.nextUrl.pathname;
    const userAgent = req.headers.get('user-agent') || '';

    // SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    if (/(\b(union|select|insert|delete|update|drop|create)\b.*\b(select|from|where)\b)/i.test(path)) {
      return true;
    }

    // XSSæ”»æ’ƒã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    if (/<script|javascript:|data:text\/html/i.test(path)) {
      return true;
    }

    // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«
    if (/\.\.[\/\\]/.test(path)) {
      return true;
    }

    // ä¸å¯©ãªUser-Agent
    if (!userAgent || userAgent.length < 10) {
      return true;
    }

    return false;
  }
}
```

---

## ã¾ã¨ã‚

ã“ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»é‹ç”¨ã‚¬ã‚¤ãƒ‰ã¯ã€PME DATAHUB ã‚·ã‚¹ãƒ†ãƒ ã®å®‰å®šã—ãŸé‹ç”¨ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªæ‰‹é †ã‚’æä¾›ã™ã‚‹ã€‚ä»¥ä¸‹ã®åŸå‰‡ã«åŸºã¥ã„ã¦é‹ç”¨ã‚’è¡Œã†ï¼š

### é‹ç”¨ã®åŸºæœ¬åŸå‰‡
1. **è‡ªå‹•åŒ–**: å¯èƒ½ãªé™ã‚Šæ‰‹å‹•æ“ä½œã‚’é¿ã‘ã€è‡ªå‹•åŒ–ã‚’æ¨é€²
2. **ç›£è¦–**: ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’ç¶™ç¶šçš„ã«ç›£è¦–ã—ã€å•é¡Œã‚’æ—©æœŸæ¤œçŸ¥
3. **å†—é•·æ€§**: å˜ä¸€éšœå®³ç‚¹ï¼ˆSPOFï¼‰ã‚’æ’é™¤ã—ã€é«˜å¯ç”¨æ€§ã‚’ç¢ºä¿
4. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: å¸¸ã«ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’æœ€å„ªå…ˆã«è€ƒæ…®
5. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–**: å…¨ã¦ã®é‹ç”¨æ‰‹é †ã‚’æ–‡æ›¸åŒ–ã—ã€å…±æœ‰

### ç¶™ç¶šçš„æ”¹å–„
- **å®šæœŸãƒ¬ãƒ“ãƒ¥ãƒ¼**: é‹ç”¨æ‰‹é †ã®å®šæœŸçš„ãªè¦‹ç›´ã—ã¨æ”¹å–„
- **ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†**: é‹ç”¨ãƒãƒ¼ãƒ ã‹ã‚‰ã®æ”¹å–„ææ¡ˆã®ç©æ¥µçš„å–ã‚Šå…¥ã‚Œ
- **æŠ€è¡“é€²åŒ–**: æ–°ã—ã„æŠ€è¡“ã‚„ãƒ„ãƒ¼ãƒ«ã®ç¶™ç¶šçš„ãªè©•ä¾¡ã¨å°å…¥

---

**ä½œæˆæ—¥**: 2025å¹´10æœˆ17æ—¥
**æœ€çµ‚æ›´æ–°**: 2025å¹´10æœˆ17æ—¥
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0

**å¯¾è±¡è€…**: ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã€é‹ç”¨ãƒãƒ¼ãƒ ã€ãƒ‡ãƒ—ãƒ­ã‚¤æ‹…å½“è€…
